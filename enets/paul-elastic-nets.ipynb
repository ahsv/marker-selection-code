{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic nets on the Paul data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as sklm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy==1.3.2+25.g8ac9c03 anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 \n"
     ]
    }
   ],
   "source": [
    "import scanpy.api as sc\n",
    "\n",
    "sc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.settings.set_figure_params(dpi=80, color_map='viridis')  # low dpi (dots per inch) yields small inline figures\n",
    "sc.logging.print_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'paul15_clusters' as categorical\n"
     ]
    }
   ],
   "source": [
    "adata = sc.datasets.paul15()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = list(adata.obs['paul15_clusters'].cat.categories)\n",
    "yVec = np.array([lookup.index( adata.obs['paul15_clusters'][i] ) for i in range(adata.obs['paul15_clusters'].shape[0]) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = np.load(\"paul15-scviFolds.npz\")['folds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 546)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the elastic net objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This alpha list was discovered after some manual testing with elastic nets.  It should run pretty quickly and rarely fail to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphaList = np.linspace(0.05, 100*0.05, num=100, endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = sklm.ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], cv=5, max_iter=10000, n_jobs=2, alphas=alphaList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Enets on cluster 0 in  fold 0\n",
    "\n",
    "It takes about 2 minutes to train this.  This means about an hour per fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(adata.X.shape[0],dtype=bool)\n",
    "mask[folds[0]] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 32s, sys: 1min 4s, total: 3min 36s\n",
      "Wall time: 1min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElasticNetCV(alphas=array([0.05, 0.1 , ..., 4.95, 5.  ]), copy_X=True, cv=5,\n",
       "       eps=0.001, fit_intercept=True,\n",
       "       l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], max_iter=10000,\n",
       "       n_alphas=100, n_jobs=2, normalize=False, positive=False,\n",
       "       precompute='auto', random_state=None, selection='cyclic',\n",
       "       tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "en.fit(adata.X[~mask], (yVec[~mask]==0)*1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selected markers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 552,  553, 1212, 1351, 1421, 1422, 2025, 2384])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(en.coef_)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the selected markers in order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempMarks = np.flipud(np.argsort(np.abs(en.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1421, 2025, 1212, ..., 2294, 2293,    0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempMarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "currMarks = []\n",
    "currCoefs = []\n",
    "\n",
    "ind = 0\n",
    "while en.coef_[tempMarks[ind]] != 0:\n",
    "    currMarks.append(tempMarks[ind])\n",
    "    currCoefs.append(en.coef_[tempMarks[ind]])\n",
    "        \n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1421, 2025, 1212, 553, 552, 1351, 1422, 2384]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currMarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mark in np.nonzero(en.coef_)[0]:\n",
    "    if mark not in currMarks:\n",
    "        print(\"ERROR: Marker {} was not duplicated\".format(mark))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the enets on a fold\n",
    "\n",
    "Specify `foldN` for the fold that you desire.  Some training and convergence information is included below (from the time that I ran the jobs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on cluster 0\n",
      "Working on cluster 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on cluster 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on cluster 3\n",
      "Working on cluster 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on cluster 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on cluster 6\n",
      "Working on cluster 7\n",
      "Working on cluster 8\n",
      "Working on cluster 9\n",
      "Working on cluster 10\n",
      "Working on cluster 11\n",
      "Working on cluster 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on cluster 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on cluster 14\n",
      "Working on cluster 15\n",
      "Working on cluster 16\n",
      "Working on cluster 17\n",
      "Working on cluster 18\n",
      "CPU times: user 1h 23min 27s, sys: 35min 17s, total: 1h 58min 45s\n",
      "Wall time: 47min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alphaList = np.linspace(0.05, 100*0.05, num=100, endpoint=True)\n",
    "\n",
    "foldN = 4\n",
    "mask = np.zeros(adata.X.shape[0],dtype=bool)\n",
    "mask[folds[foldN]] = True\n",
    "\n",
    "allMarks = []\n",
    "allCoefs = []\n",
    "\n",
    "for clust in np.unique(yVec):\n",
    "    print(\"Working on cluster {}\".format(clust))\n",
    "    en = sklm.ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], cv=5, max_iter=10000, n_jobs=2, alphas=alphaList)\n",
    "    \n",
    "    en.fit(adata.X[~mask], (yVec[~mask]==clust)*1)\n",
    "    \n",
    "    tempMarks = np.flipud(np.argsort(np.abs(en.coef_)))\n",
    "    \n",
    "    currMarks = []\n",
    "    currCoefs = []\n",
    "    \n",
    "    ind = 0\n",
    "    while en.coef_[tempMarks[ind]] != 0:\n",
    "        currMarks.append(tempMarks[ind])\n",
    "        currCoefs.append(en.coef_[tempMarks[ind]])\n",
    "        \n",
    "        ind += 1\n",
    "\n",
    "    allMarks.append(np.array(currMarks))\n",
    "    allCoefs.append(np.array(allCoefs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some timing and convergence information:\n",
    "* Fold 0 took 52 min 10s on 3 cores.  We had 18 cases where the convergence failed.\n",
    "* Fold 1 took 1hr 46 min on 2 cores (wall time 54min 16s).  We had 12 cases where the convergence failed.\n",
    "* Fold 2 took 1hr 53 min (wall time 1hr 10min).  We had 19 cases where the convergence failed.\n",
    "* Fold 3 took 2hr 13 min (wall time 1hr 9min).  We had 23 cases where the convergence failed.\n",
    "* Fold 4 took 1hr 23 min (wall time 47min).  We had 20 cases where the convergence failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12,\n",
       " 233,\n",
       " 185,\n",
       " 67,\n",
       " 43,\n",
       " 118,\n",
       " 276,\n",
       " 111,\n",
       " 110,\n",
       " 86,\n",
       " 27,\n",
       " 96,\n",
       " 169,\n",
       " 99,\n",
       " 55,\n",
       " 78,\n",
       " 9,\n",
       " 1,\n",
       " 22]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a.shape[0] for a in allMarks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"paul15-nets-fold{}-marks\".format(foldN), allMarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"paul15-nets-fold{}-coefs\".format(foldN), allCoefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff = np.load(\"paul15-nets-fold0-marks.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1421, 2025, 1212,  553,  552, 1351, 1422, 2384]),\n",
       " array([1735, 1121,  814, 1978, 2384, 1421, 1422, 3199, 3283, 3261,  532,\n",
       "        2388,  483, 1072, 1597,  582,  769,  782, 1212, 1500, 2912, 2129,\n",
       "        2563, 1058,  778,   58,  709, 2856, 2044, 1215, 2102, 1020, 1012,\n",
       "        3248, 2910, 1213,  561,  689,  881, 1032, 2796, 3226,  439,  494,\n",
       "        2105, 2940, 1502, 1039, 2054, 1860,  392,  469, 1066, 2025,  398,\n",
       "         887, 2640,  111, 1888, 2624, 1400, 1670,  362,  797, 2478,  600,\n",
       "        2634, 3428, 2436,  472,  631,  148, 2407, 1351, 2639, 3374, 2949,\n",
       "        2361,  553,  271, 1783, 2677, 3152, 2930,  209,  446, 1656,  994,\n",
       "        2263,  883,  766,   18,  604, 2636,  833, 1340, 1454,  196,  653,\n",
       "        2068,  534,  788,  248, 3230,  552, 2093, 1800,  413, 1720, 3250,\n",
       "         396, 3000, 2435,  309, 1028, 2294,  596, 2872, 1973, 3380,   62,\n",
       "        2958, 2807, 1429,  998, 2628, 2190,  285, 1081,  170,  549, 2742,\n",
       "         729,  302, 1040, 2645, 2425, 1476, 2556,  454, 3234,  412, 3309,\n",
       "        2629, 1320]),\n",
       " array([1072, 1978,  302,  163,  552, 2940, 2384, 1888, 2102,  483, 3123,\n",
       "        2610,  778,  235,  603, 2025, 1212,  549, 1953, 2388, 1036, 3449,\n",
       "        2450, 2912, 2703, 2642, 3093, 1800, 1035, 1213, 1410,  397, 1020,\n",
       "        3374, 2220, 1255, 2621,  998, 1476,  393,  600, 1298,  782, 2958,\n",
       "        3261,  553, 1351, 1049, 2624, 2195,  534, 2872, 1029, 3443, 2640,\n",
       "        1421, 1496,  881,  219,  689,  386,  835, 2546, 1699, 1971,  761,\n",
       "        1631, 2054, 2641,  694, 1783, 2629, 1955, 2205, 2479, 1893, 1365,\n",
       "         596, 3283, 3238,  995, 1913,  196,  399, 1040,  937, 3106,  768,\n",
       "        1405, 2070, 1808, 3073, 3226, 2628, 2425, 1954, 3234, 2040, 2636,\n",
       "        3439,  815,  170,  413, 3441, 1503, 1678,  392, 1320]),\n",
       " array([ 835,  814,  552, 2009, 3251, 1640,  412, 2951, 1459, 1936, 1953,\n",
       "        1121, 1212, 1954, 3446, 1800, 2590, 1320,  553, 1351, 2932, 3250,\n",
       "        2933, 2688,  246,  413, 1187, 2641, 1783,  709, 3000, 2637, 1025,\n",
       "        2626,  788, 3002,  271, 1055,  144, 1298,  766,  683, 1828, 2622,\n",
       "         532,  774,  225,  305, 1040, 2801, 2628, 3165, 1072, 1023, 2645,\n",
       "        1496, 2415,  648, 1913, 1786,  600, 3422,  997]),\n",
       " array([1953,  413, 1121,  552, 1036,  553, 2328, 1346, 2628,  778,  814,\n",
       "        2009, 2388, 1298,  998, 2415,  782, 1783,  881, 1723, 2025, 1213,\n",
       "         683, 2384, 1913, 3250, 2622, 2645, 2932,  196, 3152, 1972, 2746,\n",
       "        2801, 2044,  769, 1496]),\n",
       " array([ 305, 2729,  596,  785, 1713, 1346, 3237, 1954,  730, 2635, 2666,\n",
       "        2479, 2951, 1212, 2705, 1121, 2388, 2622,  727, 1448,  694,  761,\n",
       "         881,  235, 2930, 3032, 1320, 3226,  276,  835, 1187,  368, 1783,\n",
       "        2621, 2910, 3149,  861, 1022, 2712,  769, 2195, 2523, 1714, 1410,\n",
       "        2636,  885, 2384,  683,  309, 1248,  998, 1764,  144, 3230, 3251,\n",
       "        1733,  412,  308, 1771, 1318, 3325,  196, 1535, 2123, 3279, 2414,\n",
       "         553, 1351,  413, 1971, 1371,  603, 3309,  552, 1923, 2576, 2044,\n",
       "         803, 2645, 1913,  548,  400, 2129, 1838, 3250,  766,  602, 3099,\n",
       "        2431,  997,  774,  869, 2105, 2875, 2640, 1040, 3190, 1536,  729,\n",
       "        2425, 1962, 3374,  994,  814, 1249, 1740, 1025, 2088, 1497, 3152,\n",
       "        1496, 1213,  393,  483, 2761, 1429,  532, 2430, 1500, 1800, 1888,\n",
       "        1093]),\n",
       " array([3237, 1740,  305,  314, 2898, 2776, 1389, 2909,   49, 1869, 2068,\n",
       "         785,  566, 1253, 1400, 3325, 1317, 1652,  874,  590,  357, 1535,\n",
       "        2521, 3344, 1751, 1435, 3274,  885,  483,   63,  437, 1206, 2641,\n",
       "         833, 2381, 1795, 1837, 2250,  683, 2845, 2721, 1601, 2422,  621,\n",
       "        1583, 1497, 2026, 1409, 1250,  413, 2205, 1770, 1222, 1805, 1838,\n",
       "        2235, 3332,  334, 2035, 1510, 1118, 2666, 2761, 2040,  600,  330,\n",
       "         406,   44,  602, 1228,  350, 1800, 3226, 3441, 3380, 1539, 1739,\n",
       "        1509, 1714, 2054, 2481, 1726,  743,  371, 2628,  412,  331,  718,\n",
       "        2067,  769, 1568, 3099, 1121, 1213, 3374, 1506, 3190, 3000, 2436,\n",
       "        1126,  148, 3309, 2635, 1408, 1188, 2637, 1319, 2711,  826, 2621,\n",
       "         937, 2701,  392, 1581, 3002,  729, 1723,  494, 2951,  356,  797,\n",
       "        2105, 3240,  362, 2807, 1320, 1405, 2390,  285, 1783, 1072, 1252,\n",
       "        1493, 2576, 3257,  883, 2640,  995,  271,  727, 1187,  284, 3152,\n",
       "        1953, 2958,  196, 3074, 1429, 1955,  549, 1503, 1496, 3428,  144,\n",
       "        2005, 3259, 2523, 1430, 3049,   32,  993,  378, 1764,  248,  815,\n",
       "         533, 2425,  498, 3286, 1295, 2629,  243, 2712, 2873, 2551,  552,\n",
       "        1474, 1913, 2626,  534, 2930, 1454,  114, 1670,  998,  997, 1346,\n",
       "        1773, 3279, 1972, 1263, 1505, 1835, 2361, 2444, 1365,  211,   30,\n",
       "        2739, 3092, 3250, 2038, 2431, 1010, 1024, 3081, 3283,  788, 1029,\n",
       "        1325, 2025, 1410, 1351, 2634, 2435,  761,  170, 1190, 1825, 2645,\n",
       "        3204, 1040, 1098, 3162, 1700, 3121, 2872, 1781,  603, 1318, 1066,\n",
       "        2941, 2448, 2045,  936,  532, 1906, 1396, 1367]),\n",
       " array([2250, 1601, 1102, 2203, 2729,  861,  708, 2113, 2528,  632, 1253,\n",
       "        1855, 2787, 1346, 3049, 2479, 1971, 3428,  590, 1451, 3446, 1783,\n",
       "        1410,    2, 1118, 2522, 1469, 1535, 1781, 1083,  494, 1212, 3274,\n",
       "        2609, 1035,  151, 2390,  437,  683, 1894, 1032, 2930, 1428,  710,\n",
       "        3123,  697, 1010,  356,  285,  566,  803, 1409, 1973, 1072, 1019,\n",
       "        2025, 1888, 2640, 1913, 2952, 1497, 2637, 1371, 3002, 2636,  495,\n",
       "        3441, 3250, 1411, 2780,  413,  552, 1351, 3265, 3444, 1040,  400,\n",
       "        3374,  196, 1699,  452, 2874,  534, 3433, 1537,  553, 2513, 2628,\n",
       "         644, 3152, 1298, 2471, 1024, 1405, 1496,  628, 3074, 2626, 3230,\n",
       "         439, 2872,  395,  815, 2635, 1296, 2425]),\n",
       " array([1346, 2729, 2919, 2898, 3337, 3099,  243,  761, 2331, 1835, 1720,\n",
       "         693, 2647, 1410,  785, 1118, 1836, 1143, 2250, 1893,  398, 1660,\n",
       "         861,  774, 2068, 3214, 2939,  276, 1913, 2930, 1515, 2030, 1781,\n",
       "         744,  833,  863, 2641, 1320,  259, 1783, 2664, 1502, 1018,  534,\n",
       "        1127, 2637, 2950, 3152, 2622,  890, 1028,  549,  413, 2628,  815,\n",
       "        1040,  803, 2106,  596, 2054, 1726, 2666, 1351, 1590, 1699,  397,\n",
       "        1121, 1535, 2072,  935, 3283, 2932,  144, 2872,  766, 2384, 2173,\n",
       "         330,  852,  501, 1036, 2624, 2146, 2556, 2801, 3441, 2640, 3279,\n",
       "        1408, 3265,  998,  604,  170, 2479, 1496,  439,  393, 2025,  552,\n",
       "        3230, 1690, 3374, 3206]),\n",
       " array([ 941, 1193, 2718,  305, 1346, 3099, 1410,  590,  613, 1772, 1188,\n",
       "        1740, 2250, 2113, 1784, 2479, 2676, 1048, 2729, 1163, 1729, 3182,\n",
       "        2047, 1297,  476, 1049, 3237,  533, 3204,  628, 3251, 1515, 1739,\n",
       "          66, 2133, 2761, 2930, 3356, 1838,  222, 2068, 1024, 2173, 1720,\n",
       "        2898, 3243, 2195,  395, 2553, 2749, 2052, 1655, 2130,  398,  331,\n",
       "        1913,  863, 2513, 3230, 3312,  803,  893, 1700, 2890, 3121,  379,\n",
       "         523, 1212, 1087, 2939, 1151, 1367,  270, 3283, 2701, 2872, 2430,\n",
       "        3240, 2521, 2621, 1699,  139,  548, 2619,  998, 2523,  774, 3175,\n",
       "         268, 1040,  362,  276, 1891, 1714, 2640, 2425, 1323, 1320,  483,\n",
       "        3380,  199, 1670, 3428, 2847,  830, 1378, 1004, 2325,  534,  518,\n",
       "        1101, 2304, 2556, 2119, 3002, 1764,  673, 1026, 1118,  392,  766,\n",
       "        2726, 1443, 3245, 2932,  815, 2743,  232, 2641, 3190, 1837,  640,\n",
       "         779,  596, 3085,  148, 1213, 1036, 2235, 2097, 3449, 2647, 2769,\n",
       "         219,  936,  144, 1216, 2476,  873, 3226, 2950, 2634, 1787,  648,\n",
       "        2088, 1022, 2387,  501,  729, 1083, 2016, 1971, 2374,  876,  551,\n",
       "        2623, 1253, 2037, 2926,  225, 1997, 2856, 1348, 1590, 2873, 2624,\n",
       "        1506,  552, 2649, 2143,  508, 1447,  397,  249, 2636, 2175,  993,\n",
       "         399,  196, 2197, 2721, 1249, 1120, 3446, 1568, 1020,  997,  309,\n",
       "         932,  553,  645,  604, 1187,    5, 1478,  393,  995, 1407, 3310,\n",
       "        3074, 1846, 3092,  330, 1431, 1064, 2888, 1021, 1781,  304, 1930,\n",
       "        3265, 2092,  688, 2610, 2635, 3250, 3149, 3437, 1657,   30,  884,\n",
       "        2007,  869, 2103, 2628,  394, 2025,  413, 1783, 2426, 1409, 3278,\n",
       "         734, 2222,  187, 1800,  600, 2801, 1351,  985, 1298,  542, 2742,\n",
       "        2390, 1690,  430, 3100, 3047, 1143,  350, 2626, 1502, 1496,  638,\n",
       "         782]),\n",
       " array([ 628,  803, 1410, 2640, 1913,  196, 2628, 1320, 2425, 1496]),\n",
       " array([1740, 1535,  738,  305, 1428, 1253, 2594, 2422, 1219, 3237, 1783,\n",
       "        1720, 2930, 1977, 2113, 3250, 1713, 1903, 1410, 1121,  596, 2729,\n",
       "        2380, 3234, 2295, 2628, 1980,  209, 1723, 2728, 1927,  151,  785,\n",
       "        2093, 1971, 2556, 3239, 1320, 2425,  395, 3002, 1213, 2634, 2390,\n",
       "        2661, 2622, 3441,  803, 1076,  144,  196, 1346, 1839, 1690, 3000,\n",
       "        2642, 1545, 1083, 2636, 3309, 1454, 1913, 1143,  553, 1448,  998,\n",
       "         331, 2768, 1430, 2631,  778, 2739,  413, 2761, 2183,  683,  330,\n",
       "         815, 1319, 2807, 2438,  170, 1030, 2513, 2640,  552, 1040, 2205,\n",
       "         727, 1771, 3190, 2872,  368,  534,  393, 1080, 1838, 1371, 1781,\n",
       "        2626]),\n",
       " array([1101,  305, 1040, 3243, 1711, 1720,  628, 1049, 1410, 2745, 2430,\n",
       "         534, 3214, 1409, 3000,  874, 2388, 1471, 1114,  604, 2479,  761,\n",
       "        2513,  553, 2761, 3250, 1783,  249, 2474, 3325, 2093, 2930,  566,\n",
       "        2425,  815, 2025,  276,  683, 1590, 3312, 1913,  285,  518, 3239,\n",
       "        2576,  994, 3309,  246,  371, 2721,  552, 1028,  413, 3374, 1953,\n",
       "        1846,  998, 1298, 2637, 3245, 2748, 1954, 3428,  785,  483, 1320,\n",
       "        3251, 2645,  602, 1670, 3004, 1800, 1121, 2636, 2106,  412, 2628,\n",
       "        1817, 3230, 2952,  778, 2263,  501]),\n",
       " array([2258, 2980, 1367, 2726,  249, 1720, 2088,  534, 2295, 2930, 2712,\n",
       "        2474, 3162,  331, 1657, 1690, 1028, 2513, 1448, 2932, 2438, 2745,\n",
       "        1766, 1733, 2146,  397,  330, 1913,  196, 1213, 1953,  410,  542,\n",
       "          58, 1545, 2390, 2025, 2173, 3099,  803, 1700, 1800, 1539, 2749,\n",
       "        2623, 1351, 1893, 2526,   15, 2376, 1072,  596, 1979,  604,  997,\n",
       "        3230, 2807,  837, 1320, 3152, 1365, 1846, 1298, 2175, 2640, 1781,\n",
       "        2622,  694, 1040,  660, 2388, 1410,  767,  947, 2435,  304, 1411,\n",
       "         276, 2628, 3226, 2425,  553, 1319, 2407, 2953, 1295,  552, 1764,\n",
       "        3190, 3206, 2888, 1783]),\n",
       " array([2088,  625,  249, 1781, 1539, 1720, 2295,  596, 2780, 1083, 1049,\n",
       "        3099, 1800,  331, 1497, 2513, 2761, 1545, 2932, 2084, 2165, 1913,\n",
       "         305, 2054,  412,  354,  144, 2728,  804, 3283, 2425, 2934,  428,\n",
       "        2930, 3154, 2126, 1213, 3027,  744, 1699,  392,  683, 2197,  534,\n",
       "        1095,  502, 2888, 1971, 2175, 3032, 2953, 1405,  664, 1318, 2328,\n",
       "        2549, 2742, 2442, 2044, 2390, 2645, 2628, 1581, 1036,  766, 1836,\n",
       "        2626,  803,  815, 2438, 1040, 3149, 1502, 2093, 2873,  782, 1700,\n",
       "         653, 3226, 2092, 2768, 2624, 2106, 2634,  761, 1212, 2509,  356,\n",
       "        2430, 3374, 1839, 2205,  998,  529, 3279, 3190, 1320, 3278, 1346,\n",
       "        1298, 1783,  196, 1026, 1953]),\n",
       " array([2258, 1367, 1781,  534, 1773, 1040, 1497, 1083,  410, 1980, 1502,\n",
       "           4, 2387, 2980, 1729, 2425,  331, 2093, 1783, 1213, 2088, 1076,\n",
       "        1699, 3190, 1448,  769, 3325,  683, 2807, 1723,  766, 1800, 1913,\n",
       "        3081, 1954, 3226, 3074, 1720,  412, 1410, 1022, 2600, 2438,  745,\n",
       "        2934,  196, 3230,  553, 1035, 1484, 1953, 1320, 1169, 2712, 2025,\n",
       "        1971,   63,  393, 1714, 2390, 3261,  815, 1244, 2622, 1631,  997,\n",
       "         993, 2405, 2633,  532, 1319,  998,  604, 1590, 2768, 1024, 2952,\n",
       "        3374, 2173, 2930, 1072,  151,  308,  354,  397, 2628, 1411, 1351]),\n",
       " array([2422, 1535, 1740, 2930, 1783, 1410, 2640,  815, 1319, 1040,  331,\n",
       "        2390, 2425, 3226, 1496, 1913, 3374, 2641,  553, 1396,  196]),\n",
       " array([2390, 2930, 1496, 2425, 1040,  196]),\n",
       " array([ 590, 2769, 1522, 3026,  621,  803,  819,  287, 1400,  305, 1351,\n",
       "        1410, 2513, 2088, 1396,  196,  998, 3441, 1320, 1213, 1913,  552,\n",
       "        1496, 2628])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python r35py37",
   "language": "python",
   "name": "r35py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
