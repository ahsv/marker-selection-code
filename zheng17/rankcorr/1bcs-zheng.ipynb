{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating and processing the 1bcs consts for (sparse) Zheng data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've done this before - previously - but I don't completely trust the scripts that I was using and I want to test the framework developed with the 10x data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahsvargo/miniconda3/envs/r35py37/lib/python3.7/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy.api as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ahsvargo/xvalid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from picturedrocks import Rocks\n",
    "from picturedrocks.performance import FoldTester, PerformanceReport, NearestCentroidClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "import scipy.sparse as spsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Replace with your own data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"/home/ahsvargo/turbo/scData/zheng17/filtered_matrices_mex/hg19/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(path + \"write/raw_data_all_nz_genes_with_clusters.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(path + \"write/raw_data_5000_genes_with_clusters.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: current 0.30 GB, difference +0.30 GB\n"
     ]
    }
   ],
   "source": [
    "sc.logging.print_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulkfolds = np.load(path + \"zheng17-5folds.npz\")\n",
    "bulkfolds = [bulkfolds[\"fold{}\".format(i)] for i in range(5)]\n",
    "\n",
    "louvfolds = np.load(path + \"zheng17-5folds-lvals.npz\")\n",
    "louvfolds = [louvfolds[\"fold{}\".format(i)] for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lookups and y vectors for the two clusterings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_lookup = list(np.unique(adata.obs['bulk_labels'].values))\n",
    "louv_lookup = list(np.unique(adata.obs['louv_labels'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulky = np.array([bulk_lookup.index( adata.obs['bulk_labels'][i] ) for i in range(adata.obs['bulk_labels'].shape[0]) ]) \n",
    "louvy = np.load(path + 'zheng17_yVec_lvals.npz')['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side note for the 5000 genes: add the louv labels into the dataset and save again.  Commented out because we don't need to do this again.  The original file - without the louv labels - is `raw_data_5000_genes.h5ad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata.obs['louv_labels'] = pd.Series( [str(a) for a in np.load(path + 'zheng17_yVec_lvals.npz')['y']], dtype=\"category\", index=adata.obs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata.write(\"./write/raw_data_5000_genes_with_clusters.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 1bcs on a fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect the information about constants - the vector of dot products (essentially the rank correlation values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(adata.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68579, 20387)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = bulkfolds\n",
    "yVec = bulky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Rocks(adata.X, yVec)\n",
    "data.X = data.X.tocsc()\n",
    "data.cs_currX = data.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csc.csc_matrix"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for fold 4, starting generation of constants\n",
      "CPU times: user 224 ms, sys: 96.3 ms, total: 321 ms\n",
      "Wall time: 318 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "foldNum = 4\n",
    "\n",
    "mask = np.zeros(data.N, dtype=bool)\n",
    "mask[folds[foldNum]] = True\n",
    "foldData = Rocks(data.X[~mask], data.y[~mask], verbose=1)\n",
    "foldData.cs_currX = foldData.X\n",
    "\n",
    "print(\"Loaded data for fold {}, starting generation of constants\".format(foldNum), flush=True)\n",
    "\n",
    "def clustConsts(clust):\n",
    "    print(\"Working on cluster {}\".format(clust), flush=True)\n",
    "    setindices = set(foldData.clusterindices[clust])\n",
    "    \n",
    "    rankvec = rankdata(foldData.clust2vec(clust+1))\n",
    "    rankvec = rankvec - rankvec.mean()\n",
    "    \n",
    "    # sparse_tau_dot automatically ranks the input vector.\n",
    "    consts = list(\n",
    "        map( lambda x: Rocks.sparse_tau_dot(\n",
    "            foldData, \n",
    "            foldData.cs_currX.getcol(x), \n",
    "            foldData.clusterindices[clust], \n",
    "            #highval=1, \n",
    "            #lowval=-1, \n",
    "            highval=rankvec.max(), \n",
    "            lowval=rankvec.min(), \n",
    "            dim=foldData.N, \n",
    "            setindices=setindices\n",
    "            ),\n",
    "            range(data.P)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return np.array(consts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on cluster 0\n",
      "Working on cluster 1\n",
      "Working on cluster 2\n",
      "Working on cluster 3\n",
      "Working on cluster 4\n",
      "Working on cluster 5\n",
      "Working on cluster 6\n",
      "Working on cluster 7\n",
      "Working on cluster 8\n",
      "Working on cluster 9\n",
      "Working on cluster 10\n",
      "CPU times: user 1min 41s, sys: 3.15 s, total: 1min 44s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "foldConsts = np.array(list( map(clustConsts, range(foldData.K)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"/home/ahsvargo/publicData/zheng/zhengFilt-fold4-rankConsts.npz\", consts=foldConsts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the s values from these consts\n",
    "\n",
    "These are the scores that we will be looking at - comparing to the input parameter $s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the consts vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "consts = [np.load(\"/home/ahsvargo/publicData/zheng/zhengFilt-fold{}-rankConsts.npz\".format(i))['consts'] for i in range(5)]\n",
    "consts = np.array(consts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 11, 5000)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the methods\n",
    "\n",
    "`stsScore` works by soft-thresholding the input and then finding the s value, `sScore` just finds the s value.  The former is good in a map, the latter could be used in a loop.\n",
    "\n",
    "In practice, I have found that using a loop (over the entries of the consts vector in an increasing manner) has some numerical instability that leads to wrong s scores when the scores are close to 1 (i.e. for the largest entries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soft threshold inVec by decreasing all entries by param\n",
    "def softThreshold(inVec, param):\n",
    "    \n",
    "    signs = np.sign(inVec)\n",
    "    inVec = inVec - param * signs\n",
    "    inVec[ np.invert(signs == np.sign(inVec)) ] = 0\n",
    "    return inVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the consts and the index to get the 1-norm of the unit version of the soft-thesholded consts vector\n",
    "def stsScore(consts, ind):\n",
    "    \n",
    "    stVec = softThreshold(consts, np.abs(consts[ind]))\n",
    "    norm = np.linalg.norm(stVec)\n",
    "    norm = norm if norm > 0 else 1\n",
    "    return np.abs( stVec / norm ).sum()\n",
    "\n",
    "# input the soft-thresholded vector to get the 1-norm of the unit version of the input\n",
    "def sScore(stVec):\n",
    "    norm = np.linalg.norm(stVec)\n",
    "    norm = norm if norm > 0 else 1\n",
    "    return np.abs( stVec / norm ).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The map version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sScores(consts):\n",
    "\n",
    "    return np.array(list(map( lambda ind: stsScore(consts, ind), range(consts.shape[0]) )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could speed this up by only looking at the largest values of the sScores.  In other methods, we only look at the top 1000 genes for each cluster, for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.71 s, sys: 42.1 ms, total: 7.75 s\n",
      "Wall time: 7.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fold0 = np.array(list(map( sScores, consts[0] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.77 s, sys: 31.3 ms, total: 7.8 s\n",
      "Wall time: 7.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fold1 = np.array(list(map( sScores, consts[1] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.95 s, sys: 693 ms, total: 8.64 s\n",
      "Wall time: 8.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fold2 = np.array(list(map( sScores, consts[2] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.09 s, sys: 40.9 ms, total: 8.13 s\n",
      "Wall time: 8.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fold3 = np.array(list(map( sScores, consts[3] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.96 s, sys: 12.5 ms, total: 7.98 s\n",
      "Wall time: 7.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fold4 = np.array(list(map( sScores, consts[4] )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"zhengFilt-rankCorr-sValues.npz\", svals=np.array([fold0, fold1, fold2, fold3, fold4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "svals=np.array([fold0, fold1, fold2, fold3, fold4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 11, 5000)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the markers for a given value of lamb ($s$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to do a union of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set().union(*[np.where(clust <= 1.2)[0] for clust in svals[0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svals should be a folds x clusters x genes array\n",
    "def findMarkers(svals, lamb):\n",
    "    # Stay consistent with the Rocks code\n",
    "    lamb = np.sqrt(lamb)\n",
    "    \n",
    "    # only want the positions in each row\n",
    "    marks = []\n",
    "    for fold in svals:\n",
    "        foldMarks = list(set().union(*[np.where(clust < lamb)[0] for clust in fold]))\n",
    "        marks.append(foldMarks)\n",
    "    \n",
    "    return marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self):\n",
    "        self.traindata = None\n",
    "        self.RFC = RandomForestClassifier(n_estimators=100, n_jobs=-1, verbose=1)\n",
    "        \n",
    "    def train(self, data, yVec):\n",
    "        self.traindata = data\n",
    "        self.RFC.fit(data, yVec)\n",
    "        \n",
    "    def test(self, Xtest, sparse):\n",
    "        return self.RFC.predict(Xtest)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to log normalize the data before including it here.\n",
    "\n",
    "class NearestCentroid:\n",
    "    def __init__(self):\n",
    "        self.traindata = None\n",
    "        self.xkibar = None\n",
    "        self.clusterindices ={}\n",
    "    \n",
    "    def train(self, data, yVec, sparse=True):\n",
    "        self.traindata = data\n",
    "        \n",
    "        self.order = np.unique(yVec)\n",
    "        \n",
    "        for ind in self.order:\n",
    "            self.clusterindices[ind] = np.nonzero(yVec == ind)[0]\n",
    "        \n",
    "        if sparse:\n",
    "            self.xkibar = np.array([ \n",
    "                np.squeeze(\n",
    "                    np.asarray( data[self.clusterindices[ind]].mean(axis=0) )\n",
    "                ) for ind in self.order\n",
    "                ])\n",
    "        else:\n",
    "            self.xkibar = np.array([data[indices].mean(axis=0) for\n",
    "                indices in self.clusterindices])\n",
    "            \n",
    "    def test(self, Xtest, sparse):\n",
    "        if sparse:\n",
    "            dxixk = scipy.spatial.distance.cdist(np.squeeze(np.asarray(Xtest.todense())), self.xkibar)\n",
    "        else:\n",
    "            dxixk = scipy.spatial.distance.cdist(Xtest, self.xkibar)\n",
    "\n",
    "        return self.order[dxixk.argmin(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize before classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = \"bulk\"\n",
    "sc.pp.normalize_per_cell(adata, counts_per_cell_after=10000)\n",
    "sc.pp.log1p( adata )\n",
    "#data = Rocks(adata.X, bulky)\n",
    "#data.normalize(totalexpr=10000, log=True)\n",
    "#ft = FoldTester(data)\n",
    "\n",
    "#ft.loadfolds(path + \"zheng17-5folds.npz\")\n",
    "\n",
    "#ft.makerocks(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the number of errors for a set of markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(adata, yVec, folds, marks, lookup=None, classifier=RandomForest, debug=True):\n",
    "    \n",
    "    yhat = np.zeros(yVec.shape[0])\n",
    "    \n",
    "    for i, fold in enumerate(folds):\n",
    "        if debug:\n",
    "            print(\"*** Working on fold {} ***\".format(i), flush = True)\n",
    "            \n",
    "        mask = np.zeros(adata.X.shape[0], dtype=bool)\n",
    "        mask[fold] = True\n",
    "        \n",
    "        markers = marks[i]\n",
    "        # I haven't really tested this.  I don't think that it will save much time.\n",
    "        if lookup is not None:\n",
    "            markers = [lookup.index(mark) for mark in markers]\n",
    "        \n",
    "        # adata.X should be sparse.csc_matrix\n",
    "        if not spsp.isspmatrix_csc(adata.X):\n",
    "            adata.X = adata.X.tocsc()\n",
    "        \n",
    "        \n",
    "        train_data = adata.X[:, markers]\n",
    "        if debug: \n",
    "            print(\"Type of training data: {}\".format(type(train_data)))\n",
    "        \n",
    "        # convert to csr to quickly get the million rows\n",
    "        train_data = train_data.tocsr()\n",
    "        if debug: \n",
    "            print(\"Type of training data: {}\".format(type(train_data)))\n",
    "            \n",
    "        train_data = train_data[~mask,:]\n",
    "        \n",
    "        # convert back to csc for the classification\n",
    "        train_data = train_data.tocsc()\n",
    "        if debug: \n",
    "            print(\"Type of training data: {}\".format(type(train_data)))\n",
    "\n",
    "        # could maybe test to see if this will help speed things up...\n",
    "        #train_data = train_data.X.todense()\n",
    "        \n",
    "        if debug:\n",
    "            print(\"Size of training data: {}\".format(train_data.shape))\n",
    "            print(\"Training on fold {}\".format(i), flush=True)\n",
    "            \n",
    "        fold_classifier = classifier()\n",
    "        fold_classifier.train(train_data, yVec[~mask])\n",
    "        \n",
    "        if debug:\n",
    "            print(\"Testing on fold {}\".format(i), flush=True)\n",
    "        \n",
    "        test_data = adata.X[:, markers]\n",
    "        test_data = test_data.tocsr()\n",
    "        test_data = test_data[mask,:]\n",
    "        test_data = test_data.tocsc()\n",
    "\n",
    "        if debug:\n",
    "            print(\"Size of test data: {}\".format(test_data.shape))\n",
    "\n",
    "        \n",
    "        yhat[mask] =  fold_classifier.test( test_data, True)\n",
    "        \n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find one data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Working on fold 0 ***\n",
      "Type of training data: <class 'scipy.sparse.csc.csc_matrix'>\n",
      "Type of training data: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Type of training data: <class 'scipy.sparse.csc.csc_matrix'>\n",
      "Size of training data: (54863, 21)\n",
      "Training on fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    8.0s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test data: (13716, 21)\n",
      "*** Working on fold 1 ***\n",
      "Type of training data: <class 'scipy.sparse.csc.csc_matrix'>\n",
      "Type of training data: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Type of training data: <class 'scipy.sparse.csc.csc_matrix'>\n",
      "Size of training data: (54863, 23)\n",
      "Training on fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    9.3s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test data: (13716, 23)\n",
      "*** Working on fold 2 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of training data: <class 'scipy.sparse.csc.csc_matrix'>\n",
      "Type of training data: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Type of training data: <class 'scipy.sparse.csc.csc_matrix'>\n",
      "Size of training data: (54863, 21)\n",
      "Training on fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    7.6s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test data: (13716, 21)\n",
      "*** Working on fold 3 ***\n",
      "Type of training data: <class 'scipy.sparse.csc.csc_matrix'>\n",
      "Type of training data: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Type of training data: <class 'scipy.sparse.csc.csc_matrix'>\n",
      "Size of training data: (54863, 23)\n",
      "Training on fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    8.8s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test data: (13716, 23)\n",
      "*** Working on fold 4 ***\n",
      "Type of training data: <class 'scipy.sparse.csc.csc_matrix'>\n",
      "Type of training data: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "Type of training data: <class 'scipy.sparse.csc.csc_matrix'>\n",
      "Size of training data: (54864, 22)\n",
      "Training on fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    8.1s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test data: (13715, 22)\n",
      "CPU times: user 5min 41s, sys: 8.05 s, total: 5min 49s\n",
      "Wall time: 46.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "marks = findMarkers(svals, 1.2**2)\n",
    "yhat = classify(adata, yVec, folds, marks, lookup=None, debug=True, classifier=RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60, 72, 67, 66, 77]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marks = findMarkers(svals, 1.5**2)\n",
    "[len(a) for a in marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8516601291940682"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(yhat == yVec)[0].shape[0]/yVec.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20999"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.X.shape[0] - np.where(yhat == yVec)[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33838"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.X.shape[0] - np.where(yhat == yVec)[0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate data for a bunch of $s$ values using Nearest Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sValFile = np.load(\"zheng-rankCorr-sValues-louv.npz\")\n",
    "svals = sValFile['svals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = louvfolds\n",
    "yVec = louvy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on s = 1.0\n",
      "CPU times: user 219 ms, sys: 4.96 ms, total: 224 ms\n",
      "Wall time: 223 ms\n",
      "Working on s = 1.25\n",
      "CPU times: user 368 ms, sys: 996 µs, total: 369 ms\n",
      "Wall time: 369 ms\n",
      "Working on s = 1.5\n",
      "CPU times: user 633 ms, sys: 2.03 ms, total: 635 ms\n",
      "Wall time: 636 ms\n",
      "Working on s = 1.75\n",
      "CPU times: user 974 ms, sys: 1e+03 µs, total: 975 ms\n",
      "Wall time: 975 ms\n",
      "Working on s = 2.0\n",
      "CPU times: user 1.27 s, sys: 6.05 ms, total: 1.28 s\n",
      "Wall time: 1.28 s\n",
      "Working on s = 2.25\n",
      "CPU times: user 1.91 s, sys: 44 ms, total: 1.96 s\n",
      "Wall time: 1.96 s\n",
      "Working on s = 2.5\n",
      "CPU times: user 3.03 s, sys: 128 ms, total: 3.16 s\n",
      "Wall time: 3.16 s\n",
      "Working on s = 2.75\n",
      "CPU times: user 3.75 s, sys: 463 ms, total: 4.21 s\n",
      "Wall time: 4.22 s\n",
      "Working on s = 3.0\n",
      "CPU times: user 5.14 s, sys: 420 ms, total: 5.56 s\n",
      "Wall time: 5.56 s\n",
      "Working on s = 3.25\n",
      "CPU times: user 5.26 s, sys: 568 ms, total: 5.83 s\n",
      "Wall time: 5.83 s\n",
      "Working on s = 3.5\n",
      "CPU times: user 5.58 s, sys: 815 ms, total: 6.39 s\n",
      "Wall time: 6.39 s\n",
      "Working on s = 3.75\n",
      "CPU times: user 6.15 s, sys: 940 ms, total: 7.09 s\n",
      "Wall time: 7.09 s\n",
      "Working on s = 4.0\n",
      "CPU times: user 7.23 s, sys: 731 ms, total: 7.96 s\n",
      "Wall time: 7.97 s\n",
      "Working on s = 4.25\n",
      "CPU times: user 7.21 s, sys: 544 ms, total: 7.76 s\n",
      "Wall time: 7.76 s\n",
      "Working on s = 4.5\n",
      "CPU times: user 7.67 s, sys: 559 ms, total: 8.23 s\n",
      "Wall time: 8.23 s\n",
      "Working on s = 4.75\n",
      "CPU times: user 8.76 s, sys: 878 ms, total: 9.63 s\n",
      "Wall time: 9.63 s\n",
      "Working on s = 5.0\n",
      "CPU times: user 8.54 s, sys: 619 ms, total: 9.16 s\n",
      "Wall time: 9.16 s\n",
      "Working on s = 5.25\n",
      "CPU times: user 8.82 s, sys: 741 ms, total: 9.56 s\n",
      "Wall time: 9.56 s\n",
      "Working on s = 5.5\n",
      "CPU times: user 9.24 s, sys: 747 ms, total: 9.98 s\n",
      "Wall time: 9.98 s\n",
      "Working on s = 5.75\n",
      "CPU times: user 9.78 s, sys: 802 ms, total: 10.6 s\n",
      "Wall time: 10.6 s\n",
      "Working on s = 6.0\n",
      "CPU times: user 10.4 s, sys: 890 ms, total: 11.3 s\n",
      "Wall time: 11.3 s\n",
      "CPU times: user 1min 52s, sys: 10 s, total: 2min 2s\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xvals = []\n",
    "lvals = []\n",
    "yhats = []\n",
    "\n",
    "for val in range(21):\n",
    "    lamb = 1.0 + 0.25*val\n",
    "    lvals.append(lamb)\n",
    "    print(\"Working on s = {}\".format(lamb), flush=True)\n",
    "\n",
    "    marks = findMarkers(svals, lamb**2)\n",
    "    xvals.append([len(a) for a in marks])\n",
    "    \n",
    "    %time yhat = classify(adata, yVec, folds, marks, lookup=None, debug=False, classifier=NearestCentroid)\n",
    "    yhats.append(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  12. ,   36.6,   65.6,   90. ,  117.2,  159.6,  204.8,  250. ,\n",
       "        292.6,  337.4,  386.8,  444.4,  499.8,  558.6,  618.4,  685.2,\n",
       "        754.2,  824.2,  900.2,  988.4, 1082.8])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.array(a).mean() for a in xvals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = np.array(list( map(lambda yhat: adata.X.shape[0] - np.where(yhat == louvy)[0].shape[0], yhats) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19752, 11805, 10585,  9496,  8852,  8435,  7719,  7243,  7053,\n",
       "        6887,  6819,  6663,  6517,  6436,  6422,  6380,  6362,  6360,\n",
       "        6315,  6368,  6290])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19876, 11391, 10148,  8996,  8225,  7596,  7372,  7112,  7043,\n",
       "        6896,  6840,  6753,  6629,  6496,  6409,  6389,  6377,  6395,\n",
       "        6368,  6365,  6371])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list( map(lambda yhat: adata.X.shape[0] - np.where(yhat == louvy)[0].shape[0], yhats) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68579, 5000)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"zheng-rankCorr-louv-plotInfo.npz\", xvals=xvals, yhats=yhats, ytrue=bulky, lvals=lvals, errs=errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff = np.load(\"zhengFilt-rankCorr-louv-plotInfo.npz\")['yhats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11.6,  22.6,  34. ,  50.6,  70.4,  90.8, 113.4, 137. , 174.4,\n",
       "       210.4, 239.8, 276.6, 310.8, 345.6, 384.4, 416.6, 453.2, 489.4,\n",
       "       531.6, 568.6, 606. ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.array(a).mean() for a in stuff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37401, 33718, 32278, 31628, 31312, 30575, 30256, 29732, 28903,\n",
       "       28682, 28526, 28484, 28395, 28328, 28323, 28314, 28248, 28203,\n",
       "       28087, 27830, 27679])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list( map(lambda yhat: adata.X.shape[0] - np.where(yhat == bulky)[0].shape[0], stuff) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python r35py37",
   "language": "python",
   "name": "r35py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
